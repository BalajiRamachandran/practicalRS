{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommenders 1\n",
    "\n",
    "Here we explore simple matrix factorization models on the [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "## Quick Recap\n",
    "\n",
    "On the internet, people rate items (or simply click on them, showing preference).\n",
    "\n",
    "The matrix of all ratings -- of size (n_user,n_item) -- is highly sparse. Indeed, no one rates everything, people only rate a subset of items.\n",
    "\n",
    "Recommendation (more specifically **collaborative filtering**) goal is to fill this matrix, by predicting preference or rating.\n",
    "\n",
    "The most used algorithms for such tasks are matrix factorization ones: it takes advantage from the fact that a matrix can be decomposed into two sub-matrices.\n",
    "\n",
    "In this practical session, we will explore how to use matrix factorization for collaborative filtering\n",
    "\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Rating matrices are highly sparse (there are many missing ratings).\n",
    "# Therefore, the use of sparse matrices is recommended.\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "# Data file is a CSV\n",
    "with open(\"dataset/ml-latest-small/ratings.csv\") as ratings:\n",
    "    rating_data = ratings.readlines()\n",
    "\n",
    "# We separate the header from actual data\n",
    "header = rating_data[0]\n",
    "print(header)\n",
    "\n",
    "# Data is CSV: userID,itemID,rating,timestamp\n",
    "rating_data = rating_data[1:] #contains list(tuple(uid,iid,rating,timestamp))\n",
    "\n",
    "\n",
    "# Helper to transform one \"str\" line to a tuple\n",
    "def line2tuple(l):\n",
    "    uid,iid,rating, timestamp = l.strip().split(\",\")\n",
    "    return (int(uid),int(iid),float(rating), int(timestamp))\n",
    "\n",
    "# generator for one line. (enables direct unpacking)\n",
    "def tl(l):\n",
    "    for x in l:\n",
    "        yield(line2tuple(x))\n",
    "\n",
    "# We first remap users and item to ids between (0,len(user)) and (0,len(item))\n",
    "u_dic = {}\n",
    "i_dic = {}\n",
    "        \n",
    "for uid,iid,rating,ts in tl(rating_data):  # iterating on all data\n",
    "    uk = u_dic.setdefault(uid,len(u_dic))\n",
    "    ik = i_dic.setdefault(iid,len(i_dic))\n",
    "\n",
    "num_user = len(u_dic)\n",
    "num_item = len(i_dic)\n",
    "\n",
    "print(\"there are \"+str((num_user,num_item)) +\" users and items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization on full rating matrix\n",
    "\n",
    "Factorizing a matrices into two submatrices yields latent representations of users and items. \n",
    "\n",
    "In this first part, we aim at visualizing obtained item embeddings.\n",
    "We propose to use the following function `save_embeddings` and [the tensorflow projector](http://projector.tensorflow.org/) to visualize obtained latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function saves embeddings (a numpy array) and associated labels into tsv files.\n",
    "\n",
    "def save_embeddings(embs,dict_label,path):\n",
    "    \"\"\"\n",
    "    embs is Numpy.array(N,size)\n",
    "    dict_label is {str(word)->int(idx)} or {int(idx)->str(word)}\n",
    "    \"\"\"\n",
    "    def int_first(k,v):\n",
    "        if type(k) == int:\n",
    "            return (k,v)\n",
    "        else:\n",
    "            return (v,k)\n",
    "\n",
    "    np.savetxt(f\"{path}_vectors.tsv\", embs, delimiter=\"\\t\")\n",
    "\n",
    "    #labels \n",
    "    if dict_label:\n",
    "        sorted_labs = np.array([lab for idx,lab in sorted([int_first(k,v) for k,v in dict_label.items()])])\n",
    "        print(sorted_labs)\n",
    "        with open(f\"{path}_metadata.tsv\",\"w\") as metadata_file:\n",
    "            for x in sorted_labs: #hack for space\n",
    "                if len(x.strip()) == 0:\n",
    "                    x = f\"space-{len(x)}\"\n",
    "                    \n",
    "                metadata_file.write(f\"{x}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  First task: decompose rating matrix with NMF and visualize items\n",
    "\n",
    "Three things to do:\n",
    "    - Create sparse matrix of ratings\n",
    "    - Factorize matrix with NMF into U (user sub-matrix) and I (item sub-matrix)\n",
    "    - Extract item labels (movie titles) and save embeddings/labels with preceding function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# (1) Create sparse matrix from all ratings\n",
    "Full = dok_matrix((num_user, num_item), dtype=np.float32)\n",
    "\n",
    "for uid,iid,rating,ts in tl(rating_data):\n",
    "    Full[u_dic[uid],i_dic[iid]] = float(rating) #don't forget to remap users and items\n",
    "    \n",
    "\n",
    "    \n",
    "# (2) Factorizing matrix\n",
    "\n",
    "model = NMF(n_components=25, init='random', random_state=0, max_iter=350)\n",
    "U = model.fit_transform(Full) #users\n",
    "I = model.components_      #items\n",
    "\n",
    "I = I.transpose()\n",
    "I.shape\n",
    "\n",
    "# (3) Loading labels and saving embeddings + vectors\n",
    "\n",
    "\n",
    "# data is csv with header\n",
    "with open(\"dataset/ml-latest-small/movies.csv\") as movies:\n",
    "    movie_data = movies.readlines()\n",
    "\n",
    "# print header\n",
    "print(movie_data[0])\n",
    "\n",
    "# id-> title dictionnary\n",
    "movie_names = {}\n",
    "\n",
    "for x in movie_data[1:]:\n",
    "    iid, title, *rest =  x.split(',')\n",
    "    \n",
    "    iid = float(iid)\n",
    "    \n",
    "\n",
    "    if iid in i_dic:\n",
    "        movie_names[i_dic[iid]] = title\n",
    "\n",
    "\n",
    "####################################\n",
    " \n",
    "# Saving into \"item_50_vectors.tsv\" and \"item_50_metadata.tsv\".\n",
    "save_embeddings(I,movie_names,\"item_50\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[Saved vectors/label can be visualized in tensorflow projector](http://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering  by predicting ratings:\n",
    "\n",
    "The Netflix competition introduced this framework: the goal is to predict missing ratings using existing ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Building Train/Test set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We take 10% of the train set as test data\n",
    "train_mat = dok_matrix((num_user, num_item), dtype=np.float32)\n",
    "test = []\n",
    "train = []\n",
    "    \n",
    "for i,(uid,iid,rating,ts) in enumerate(tl(rating_data)):\n",
    "    if i%10 == 0: #one out of 10 is for test\n",
    "        test.append((uid,iid,rating))\n",
    "    else:\n",
    "        train.append((uid,iid,rating))\n",
    "        train_mat[u_dic[int(uid)],i_dic[int(iid)]] = rating\n",
    "    \n",
    "print(\"Number of train examples: \", train_mat.nnz)\n",
    "print(\"Number of test examples: \", len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluating error **:\n",
    "\n",
    "The goal is to minimize the mean difference between the $n$ predicted and true ratings (respectively $\\hat{r_{ui}}, r_{ui}$). \n",
    "\n",
    "Two common metrics are the Mean Squared Error (MSE) $$\\frac{1}{n}\\sum^1_n (r_{ui}-\\hat{r_{ui}})^2$$ and the Mean Absolute Error (MAE) $$\\frac{1}{n}\\sum^1_n abs(r_{ui}-\\hat{r_{ui}})$$.\n",
    "\n",
    "## 1 ) Complete error functions (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take as input a list of differences between prediction and truth.\n",
    "\n",
    "def MSE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    computes MSE from real-pred difference\n",
    "    \"\"\"\n",
    "    return ########\n",
    "\n",
    "def MAE_err(truth,pred):\n",
    "    \"\"\"\n",
    "    computes MAE from real-pred difference\n",
    "    \"\"\"\n",
    "    return ###########\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Vanilla NMF AND SVD for rating prediction\n",
    "\n",
    "First, we test two simple models:\n",
    "- Non Negative Matrix Factorization\n",
    "- SVD\n",
    "\n",
    "The goal is to minimize the following\n",
    "\n",
    "## $$\\min\\limits_{U,I}\\sum\\limits_{(u,i)} (r_{ui} -  I_i^TU_u)^2 $$\n",
    "\n",
    "in order to have the following **prediction rule**: \n",
    "\n",
    "## $$r_{ui} = U_u.I_i $$\n",
    "\n",
    "## (TODO) What to do: \n",
    "\n",
    "- (1) complete prediction function\n",
    "- (2) fit nmf model and get User and Item profiles \n",
    "- (3) fit svd model and get User and Item profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "\n",
    "\n",
    "def pred_func(U,I,uid,iid):\n",
    "    u_p = U[uid,:]\n",
    "    i_p = I[:,iid]\n",
    "    \n",
    "    return ######                                      # TO COMPLETE (see preceding prediction rule)\n",
    "\n",
    "print(\"----------------------NMF---------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "## NMF model\n",
    "model = NMF(n_components=100, solver='cd' ,random_state=0, max_iter=100,alpha=5,l1_ratio=0.5)\n",
    "#fit and get\n",
    "U_nmf =  #users profiles                      # TO COMPLETE                                                                      \n",
    "I_nmf =  #items profiles                       # TO COMPLETE\n",
    "\n",
    "\n",
    "## Getting the truth values\n",
    "truth_tr = np.array([rating for (uid,iid),rating in train_mat.items()])\n",
    "truth_te = np.array([ rating for uid,iid,rating in test])\n",
    "\n",
    "## Predicting the ratings\n",
    "prediction_tr = np.array([pred_func(U,I, uid,iid) for (uid,iid),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func(U,I,u_dic[uid],i_dic[iid]) for uid,iid,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "    \n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))\n",
    "\n",
    "\n",
    "print(\"----------------------SVD---------------------------\")\n",
    "\n",
    "## SVD Model\n",
    "\n",
    "model = TruncatedSVD(n_components=150)\n",
    "U_svd =  #users profiles                                             # TO COMPLETE\n",
    "I_svd =  #items profiles                                             # TO COMPLETE \n",
    "\n",
    "## We already have the truth values, we just predict\n",
    "prediction_tr = np.array([pred_func(U,I, uid,iid) for (uid,iid),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func(U,I,u_dic[uid],i_dic[iid]) for uid,iid,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "    \n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Regularization\n",
    "\n",
    "\n",
    "Trying to model the ratings this way is highly prone to overfitting: The train error is low, but the test error is much higher. Traditionnally, models are highly regularized to achieve better performances\n",
    "\n",
    "$$\n",
    "\\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  I_i^TU_u)^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2)}_\\text{regularization}\n",
    "$$\n",
    "\n",
    "**Mean normalization** is also a common way to improve performance. In fact, the global mean is the first baseline to try when doing rating prediction\n",
    "\n",
    "\n",
    "## (TODO) Mean baseline:\n",
    "\n",
    "To get the mean baseline:\n",
    "\n",
    "- (1) compute training set mean\n",
    "- (2) complete prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"----------------------MEAN ONLY---------------------------\")\n",
    "\n",
    "\n",
    "# compute mean of list(train_mat.values())\n",
    "mean = # TO COMPLETE\n",
    "\n",
    "\n",
    "def pred_func(U,I,uid,iid):    \n",
    "    return # TO COMPLETE\n",
    "\n",
    "print(\"mean rating is \", mean)\n",
    "\n",
    "\n",
    "## We already have the truth values, we just predict\n",
    "prediction_tr = np.array([pred_func(U,I, uid,iid) for (uid,iid),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func(U,I,u_dic[uid],i_dic[iid]) for uid,iid,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "    \n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, using only the mean ratings to predict future ratings has better performances.\n",
    "\n",
    "### (TODO) Taking the mean rating into account:\n",
    "\n",
    "Most work on rating prediction model mean ratings. The goal is to only factor deviation from the mean.\n",
    "\n",
    "To take into account the mean, the easiest way is to substract it by doing the following:\n",
    "\n",
    "- (1) compute training set mean\n",
    "- (2) remove mean from training rating matrix\n",
    "- (3) factorize the normalized matrix\n",
    "- (4) when predicting a rating, simply add the mean\n",
    "\n",
    "The prediction rule becomes:\n",
    "## $$r_{ui} = \\mu + U_u.I_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "\n",
    "\n",
    "# (1) compute mean of list(train_mat.values())\n",
    "mean = # TO COMPLETE\n",
    "\n",
    "def pred_func(U,I,uid,iid):\n",
    "    # TO COMPLETE FULLY\n",
    "    \n",
    "    return # TO COMPLETE\n",
    "\n",
    "\n",
    "# (2) remove mean from training matrix\n",
    "tmn = dok_matrix((num_user, num_item), dtype=np.float32)\n",
    "\n",
    "for (uid,iid), rating in train_mat.items():\n",
    "    tmn[uid,iid] = #TO COMPLETE\n",
    "\n",
    "# (3) factorize matrix\n",
    "model_norm = TruncatedSVD(n_components=30)\n",
    "#fit \n",
    "U_msvd =  #users profiles\n",
    "I_msvd =  #items profiles\n",
    "\n",
    "\n",
    "\n",
    "## We already have the truth values, we just predict\n",
    "prediction_tr = np.array([pred_func(U,I, uid,iid) for (uid,iid),rating in train_mat.items()])\n",
    "prediction_te = np.array([pred_func(U,I,u_dic[uid],i_dic[iid]) for uid,iid,rating in test])\n",
    "\n",
    "\n",
    "print(\"Training Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_tr,truth_tr))\n",
    "print(\"MAE:\",  MAE_err(prediction_tr,truth_tr))\n",
    "    \n",
    "print(\"Test Error:\")\n",
    "print(\"MSE:\",  MSE_err(prediction_te,truth_te))\n",
    "print(\"MAE:\",  MAE_err(prediction_te,truth_te))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Collaborative Filtering and Ranking Metrics\n",
    "\n",
    "Most of the time recommender systems present $k$ items to the users. Therefore, recommenders are often evaluated by how many relevant items are in their $k$ set (using ranking metrics)\n",
    "\n",
    "Different ranking methods exists such as the [Mean Reciprocal Rank](http://en.wikipedia.org/wiki/Mean_reciprocal_rank) or the [normalized Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)\n",
    "\n",
    "## (TODO) Let's implement nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The dcg@k is the sum of the relevance, penalized gradually\n",
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        \n",
    "    return 0.\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# dcg_at_k(r, 1) => 3.0\n",
    "# dcg_at_k(r, 2) => 4.2618595071429155\n",
    "    \n",
    "\n",
    "# And it's normalized version\n",
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "    \"\"\"\n",
    "    dcg_max = # dcg_at_k(....)  # TO COMPLETE \n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# ndcg_at_k(r, 1) => 1.0\n",
    "# ndcg_at_k(r, 4) => 0.96519546960144276\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) compute nDCG\n",
    "What is nDCG for every model we tried ? ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def group_by_user(tuple_list):\n",
    "    r_dic = {}\n",
    "    for uid,iid,rating in tuple_list:\n",
    "        list_rev = r_dic.get(u_dic[uid],[])\n",
    "        list_rev.append((u_dic[uid],i_dic[iid],rating))\n",
    "    \n",
    "        r_dic[u_dic[uid]] =list_rev\n",
    "    return r_dic\n",
    "\n",
    "userg_train = group_by_user(train)\n",
    "userg_test = group_by_user(test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mean_ndcg_UI(U,I):\n",
    "    mean_ndcg = 0\n",
    "    num_users = 0\n",
    "    \n",
    "    for _,list_rating in userg_train.items():\n",
    "\n",
    "        pred_ratings = [(pred_func(U,I,uid,iid)) for uid,iid,rating in list_rating]\n",
    "        real_ratings = [rating for uid,iid,rating in list_rating]\n",
    "        pred_objects = # TO COMPLETE  tip: inverse argsort: np.argsort(pred_ratings)[::-1]\n",
    "        \n",
    "\n",
    "        mean_ndcg += ndcg_at_k(pred_objects,10)\n",
    "        num_users += 1\n",
    "\n",
    "    return  mean_ndcg/num_users\n",
    "    \n",
    "    \n",
    "def random_ndcg():\n",
    "    mean_ndcg = 0\n",
    "    num_users = 0\n",
    "    \n",
    "    for _,list_rating in userg_train.items():\n",
    "\n",
    "        real_ratings = [rating for uid,iid,rating in list_rating]\n",
    "        shuffle(real_ratings)\n",
    "        pred_objects = real_ratings\n",
    "\n",
    "        mean_ndcg += ndcg_at_k(pred_objects,10)\n",
    "        num_users += 1\n",
    "\n",
    "    return  mean_ndcg/num_users\n",
    "    \n",
    "print(\"ndcg nmf\", mean_ndcg_UI(U_nmf,I_nmf)) \n",
    "print(\"ndcg svd\", mean_ndcg_UI(U_svd,I_svd)) \n",
    "print(\"ndcg svd + mean\", mean_ndcg_UI(U_msvd,I_msvd)) \n",
    "print(\"mean == random\", random_ndcg())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
